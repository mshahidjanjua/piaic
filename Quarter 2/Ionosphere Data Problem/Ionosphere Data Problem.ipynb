
import numpy as np
import pandas as pd 
from keras.models import Model
from keras import layers
from keras import Input

#1.Load data
data = pd.read_csv("ionosphere_data.csv",sep=",") 
#print (cardata)
#2.Check Missing Values ( If Exist ; Fill each record with mean of its feature ) or any usless column.
#Shuffle the data if needed.
#Standardized the Input Variables. Hint: Centeralized the data
for x in data:
    if x == np.nan:
        print(f"Using '==' -->  {x} is a nan!")
    else:
        print(f"Using '==' -->  {x} is not a nan!")
# 3.Split into 60 and 40 ratio.
#Encode labels.
train, test  = np.split(data.sample(frac=1), [int(.6*len(data))])
#4.Model : 1 hidden layers including 16 unit.
text_vocabulary_size = 10000
question_vocabulary_size = 10000
answer_vocabulary_size = 500
num_samples = 1000
max_length = 100
text = np.random.randint(1, text_vocabulary_size,
size=(num_samples, max_length))
question = np.random.randint(1, question_vocabulary_size,size=(num_samples, max_length))
answers = np.random.randint(0, 1,size=(num_samples, answer_vocabulary_size))
model.fit([text, question], answers, epochs=10, batch_size=128)
model.fit({'text': text, 'question': question}, answers,
epochs=10, batch_size=128)
#5.Compilation Step (Note : Its a Binary problem , select loss , metrics according to it) 
#6.Train the Model with Epochs (100)
model.fit([text, question], answers, epochs=100, batch_size=128)
model.fit({'text': text, 'question': question}, answers,
epochs=10, batch_size=128)
#7.If the model gets overfit tune your model by changing the units , No. of layers , activation function , epochs , add dropout layer or add Regularizer according to the need .
model = get_model()
model.train(train)

model = get_model()
model.test(test)
#8.Evaluation Step
#Prediction should be > 92%
UPPER_ALPHA = 0.93
upper_model = GradientBoostingRegressor(loss="quantile",
                                        alpha=UPPER_ALPHA)
test_score = upper_model.evaluate(test)
train_score = upper_model.evaluate(train)
#9 Prediction
preds = model.predict(train)
print('Predicted:', decode_predictions(preds, top=3)[0])
