
import numpy as np
import pandas as pd 
from keras.models import Model
from keras import layers
from keras import Input

#1.Load data
cardata = pd.read_csv("CarPrice_Assignment.csv",sep=",") 
#print (cardata)
#2.Check Missing Values ( If Exist ; Fill each record with mean of its feature ). No missing value found
for x in cardata:
    if x == np.nan:
        print(f"Using '==' -->  {x} is a nan!")
    else:
        print(f"Using '==' -->  {x} is not a nan!")
# 3.Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).
train, test, validate  = np.split(cardata.sample(frac=1), [int(.5*len(cardata)), int(.8*len(cardata))])
#4.Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).
text_vocabulary_size = 10000
question_vocabulary_size = 10000
answer_vocabulary_size = 500
num_samples = 1000
max_length = 100
text = np.random.randint(1, text_vocabulary_size,
size=(num_samples, max_length))
question = np.random.randint(1, question_vocabulary_size,size=(num_samples, max_length))
answers = np.random.randint(0, 1,size=(num_samples, answer_vocabulary_size))
model.fit([text, question], answers, epochs=10, batch_size=128)
model.fit({'text': text, 'question': question}, answers,
epochs=10, batch_size=128)
#5.Compilation Step (Note : Its a Regression problem , select loss , metrics according to it) 
#6.Train the Model with Epochs (100) and validate it
model.fit([text, question], answers, epochs=100, batch_size=128)
model.fit({'text': text, 'question': question}, answers,
epochs=10, batch_size=128)
#7.If the model gets overfit tune your model by changing the units , No. of layers , activation function , epochs , add dropout layer or add Regularizer according to the need .
model = get_model()
model.train(train)

model = get_model()
model.test(test)
#8.Evaluation Step
test_score = model.evaluate(test)
train_score = model.evaluate(train)
validate_score = model.evaluate(validate)
#9 Prediction
preds = model.predict(train)
print('Predicted:', decode_predictions(preds, top=3)[0])
